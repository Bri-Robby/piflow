server.ip=10.0.86.98
server.port=8001

spark.master=yarn
spark.deploy.mode=cluster

fs.defaultFS=hdfs://10.0.86.191:9000

yarn.resourcemanager.hostname=10.0.86.191
#yarn.resourcemanager.address=10.0.86.191:8032
#yarn.access.namenode=hdfs://10.0.86.191:9000
#yarn.stagingDir=hdfs://10.0.86.191:9000/tmp/
#yarn.jars=hdfs://10.0.86.191:9000/user/spark/share/lib/*.jar
yarn.url=http://10.0.86.191:8088/ws/v1/cluster/apps/



hive.metastore.uris=thrift://10.0.88.71:9083

#Hdfs path, these paths will be created autometicly
#checkpoint.path=hdfs://10.0.86.89:9000/user/piflow/checkpoints/
#debug.path=hdfs://10.0.86.89:9000/user/piflow/debug/
#increment.path=hdfs://10.0.86.89:9000/user/piflow/increment/

#show data in log, set 0 if you do not show the logs
data.show=10

#monitor the throughput of flow
monitor.throughput=true

h2.port=50001


piflow.bundle=piflow-server/target/piflow-server-0.9.jar